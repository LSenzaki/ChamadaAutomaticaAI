# Guia de ComparaÃ§Ã£o de Modelos de Reconhecimento Facial

Este guia explica como usar o mÃ³dulo de comparaÃ§Ã£o para testar e comparar **face_recognition** vs **DeepFace** usando mÃ©tricas estatÃ­sticas robustas.

## ğŸ“‹ Ãndice

1. [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
2. [Estrutura do Dataset](#estrutura-do-dataset)
3. [Endpoints DisponÃ­veis](#endpoints-disponÃ­veis)
4. [Exemplos de Uso](#exemplos-de-uso)
5. [MÃ©tricas Calculadas](#mÃ©tricas-calculadas)
6. [InterpretaÃ§Ã£o dos Resultados](#interpretaÃ§Ã£o-dos-resultados)

## ğŸ”§ InstalaÃ§Ã£o

### 1. Instalar DependÃªncias

```bash
cd backend
pip install -r requirements.txt
```

As principais bibliotecas adicionadas sÃ£o:
- `face_recognition==1.3.0` - Biblioteca de reconhecimento facial baseada em dlib
- `deepface==0.0.93` - Framework com mÃºltiplos modelos de deep learning
- `scikit-learn==1.3.2` - Para cÃ¡lculo de mÃ©tricas
- `pandas==2.1.4` - ManipulaÃ§Ã£o de dados
- `matplotlib==3.8.2` e `seaborn==0.13.0` - VisualizaÃ§Ã£o
- `tf-keras==2.16.0` - Backend para DeepFace

### 2. Iniciar o Servidor

```bash
python -m uvicorn app.main:app --reload --port 8001
```

## ğŸ“ Estrutura do Dataset

Para realizar a comparaÃ§Ã£o, vocÃª precisa de um dataset estruturado:

```
test_dataset/
â”œâ”€â”€ student_1/
â”‚   â”œâ”€â”€ face_1.jpg
â”‚   â”œâ”€â”€ face_2.jpg
â”‚   â””â”€â”€ face_3.jpg
â”œâ”€â”€ student_2/
â”‚   â”œâ”€â”€ face_1.jpg
â”‚   â”œâ”€â”€ face_2.jpg
â”‚   â””â”€â”€ face_3.jpg
â””â”€â”€ student_3/
    â”œâ”€â”€ face_1.jpg
    â””â”€â”€ face_2.jpg
```

**RecomendaÃ§Ãµes:**
- MÃ­nimo de 2-3 imagens por aluno
- Imagens variadas (diferentes Ã¢ngulos, expressÃµes, iluminaÃ§Ã£o)
- Formato: JPG, JPEG ou PNG
- ResoluÃ§Ã£o mÃ­nima: 640x480px

## ğŸ› ï¸ Endpoints DisponÃ­veis

### 1. Testar Imagem Individual

```http
POST /comparison/test-single
```

Testa uma Ãºnica imagem com ambos os modelos.

**ParÃ¢metros:**
- `foto` (file): Imagem para teste
- `ground_truth_id` (int, opcional): ID real do aluno
- `deepface_model` (string): Modelo DeepFace (padrÃ£o: "Facenet512")
- `deepface_detector` (string): Detector (padrÃ£o: "opencv")
- `deepface_metric` (string): MÃ©trica de distÃ¢ncia (padrÃ£o: "cosine")

**Exemplo (curl):**
```bash
curl -X POST "http://localhost:8001/comparison/test-single" \
  -F "foto=@path/to/image.jpg" \
  -F "ground_truth_id=1" \
  -F "deepface_model=Facenet512"
```

### 2. Teste em Lote (Batch Test)

```http
POST /comparison/batch-test
```

Executa teste em lote usando um dataset completo.

**ParÃ¢metros JSON:**
```json
{
  "dataset_path": "D:/Projetos/test_dataset",
  "comparison_id": "experiment_001",
  "deepface_model": "Facenet512",
  "deepface_detector": "opencv",
  "deepface_metric": "cosine",
  "images_per_student": null
}
```

**Exemplo (Python):**
```python
import requests

response = requests.post(
    "http://localhost:8001/comparison/batch-test",
    params={
        "dataset_path": "D:/Projetos/test_dataset",
        "comparison_id": "exp_001",
        "deepface_model": "Facenet512",
        "deepface_detector": "opencv",
        "deepface_metric": "cosine"
    }
)
print(response.json())
```

### 3. Obter Resultados

```http
GET /comparison/results/{comparison_id}
```

Retorna os resultados completos de uma comparaÃ§Ã£o.

### 4. Gerar RelatÃ³rio com GrÃ¡ficos

```http
POST /comparison/generate-report/{comparison_id}
```

Gera relatÃ³rio completo com grÃ¡ficos e estatÃ­sticas.

**Exemplo:**
```bash
curl -X POST "http://localhost:8001/comparison/generate-report/exp_001?output_dir=comparison_reports"
```

### 5. Download do RelatÃ³rio

```http
GET /comparison/download-report/{comparison_id}
```

Baixa o arquivo JSON com os resultados.

### 6. Validar Dataset

```http
GET /comparison/dataset/validate?dataset_path=D:/Projetos/test_dataset
```

Valida a estrutura do dataset antes de executar testes.

### 7. Listar Modelos DisponÃ­veis

```http
GET /comparison/models/available
```

Lista todos os modelos DeepFace disponÃ­veis e suas configuraÃ§Ãµes.

**Modelos DeepFace DisponÃ­veis:**
- VGG-Face
- Facenet
- Facenet512 (recomendado)
- OpenFace
- DeepFace
- DeepID
- ArcFace
- Dlib
- SFace

## ğŸ“Š MÃ©tricas Calculadas

### 1. Cohen's Kappa (Îº)
**O que mede:** ConcordÃ¢ncia entre prediÃ§Ãµes e ground truth, ajustado para concordÃ¢ncia ao acaso.

**InterpretaÃ§Ã£o:**
- Îº < 0: Sem concordÃ¢ncia
- 0.00 - 0.20: ConcordÃ¢ncia leve
- 0.21 - 0.40: ConcordÃ¢ncia razoÃ¡vel
- 0.41 - 0.60: ConcordÃ¢ncia moderada
- 0.61 - 0.80: ConcordÃ¢ncia substancial
- 0.81 - 1.00: ConcordÃ¢ncia quase perfeita

### 2. F1 Score (Macro)
**O que mede:** MÃ©dia harmÃ´nica entre precisÃ£o e recall, calculada para cada classe separadamente.

**FÃ³rmula:** F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)

**InterpretaÃ§Ã£o:**
- 0.0 - 0.5: Desempenho ruim
- 0.5 - 0.7: Desempenho moderado
- 0.7 - 0.9: Bom desempenho
- 0.9 - 1.0: Excelente desempenho

### 3. Precision (Macro)
**O que mede:** ProporÃ§Ã£o de prediÃ§Ãµes corretas entre todas as prediÃ§Ãµes positivas.

**Quando usar:** Quando o custo de falsos positivos Ã© alto.

### 4. Recall (Macro)
**O que mede:** ProporÃ§Ã£o de casos positivos reais que foram corretamente identificados.

**Quando usar:** Quando o custo de falsos negativos Ã© alto.

### 5. Accuracy
**O que mede:** ProporÃ§Ã£o total de prediÃ§Ãµes corretas.

**LimitaÃ§Ã£o:** Pode ser enganosa em datasets desbalanceados.

### 6. Processing Time
**O que mede:** Tempo mÃ©dio de processamento por imagem.

**ImportÃ¢ncia:** Crucial para aplicaÃ§Ãµes em tempo real.

### 7. Confusion Matrix
**O que mostra:** DistribuiÃ§Ã£o de verdadeiros positivos, falsos positivos, verdadeiros negativos e falsos negativos.

## ğŸ“ˆ InterpretaÃ§Ã£o dos Resultados

### Exemplo de Resposta JSON

```json
{
  "face_recognition": {
    "accuracy": 0.85,
    "f1_macro": 0.83,
    "precision_macro": 0.84,
    "recall_macro": 0.82,
    "cohen_kappa": 0.78,
    "avg_processing_time": 0.0234,
    "total_predictions": 50,
    "valid_predictions": 48
  },
  "deepface": {
    "accuracy": 0.92,
    "f1_macro": 0.91,
    "precision_macro": 0.93,
    "recall_macro": 0.89,
    "cohen_kappa": 0.88,
    "avg_processing_time": 0.3421,
    "total_predictions": 50,
    "valid_predictions": 49
  },
  "comparison": {
    "accuracy_diff": 0.07,
    "f1_macro_diff": 0.08,
    "cohen_kappa_diff": 0.10,
    "speed_diff": -0.3187,
    "winner_accuracy": "deepface",
    "winner_f1": "deepface",
    "winner_speed": "face_recognition"
  }
}
```

### AnÃ¡lise do Exemplo

**Accuracy:**
- DeepFace: 92% vs Face Recognition: 85%
- **Vencedor:** DeepFace (+7%)

**F1 Macro:**
- DeepFace: 91% vs Face Recognition: 83%
- **Vencedor:** DeepFace (+8%)

**Cohen's Kappa:**
- DeepFace: 0.88 (concordÃ¢ncia quase perfeita)
- Face Recognition: 0.78 (concordÃ¢ncia substancial)
- **Vencedor:** DeepFace (+0.10)

**Processing Time:**
- Face Recognition: 23.4ms
- DeepFace: 342.1ms
- **Vencedor:** Face Recognition (14.6x mais rÃ¡pido)

### DecisÃ£o

**Escolha DeepFace se:**
- PrecisÃ£o Ã© prioridade mÃ¡xima
- Tempo de processamento nÃ£o Ã© crÃ­tico
- VocÃª tem recursos computacionais (GPU recomendada)
- Poucos falsos positivos sÃ£o essenciais

**Escolha Face Recognition se:**
- Velocidade Ã© crÃ­tica (tempo real)
- Recursos limitados (CPU bÃ¡sica)
- PrecisÃ£o de 85% Ã© aceitÃ¡vel
- AplicaÃ§Ã£o em dispositivos mÃ³veis/edge

## ğŸ–¼ï¸ GrÃ¡ficos Gerados

O relatÃ³rio gera automaticamente:

1. **metrics_comparison_[timestamp].png**
   - ComparaÃ§Ã£o visual de Accuracy, F1, Precision, Recall

2. **kappa_time_[timestamp].png**
   - Cohen's Kappa e tempo de processamento

3. **confusion_matrices_[timestamp].png**
   - Matrizes de confusÃ£o lado a lado

## ğŸ”¬ Casos de Uso PrÃ¡ticos

### Caso 1: ValidaÃ§Ã£o Inicial do Sistema

```python
# 1. Validar dataset
response = requests.get(
    "http://localhost:8001/comparison/dataset/validate",
    params={"dataset_path": "test_dataset"}
)

# 2. Executar teste rÃ¡pido (1 imagem por aluno)
response = requests.post(
    "http://localhost:8001/comparison/batch-test",
    params={
        "dataset_path": "test_dataset",
        "comparison_id": "quick_test",
        "images_per_student": 1
    }
)

# 3. Ver resultados
response = requests.get(
    "http://localhost:8001/comparison/results/quick_test"
)
```

### Caso 2: ComparaÃ§Ã£o Completa de Modelos DeepFace

```python
models = ["Facenet512", "ArcFace", "VGG-Face"]

for model in models:
    response = requests.post(
        "http://localhost:8001/comparison/batch-test",
        params={
            "dataset_path": "test_dataset",
            "comparison_id": f"test_{model}",
            "deepface_model": model
        }
    )
    
    # Gerar relatÃ³rio
    requests.post(
        f"http://localhost:8001/comparison/generate-report/test_{model}"
    )
```

### Caso 3: Teste A/B com Ground Truth

Cadastre alunos no sistema, depois teste reconhecimento:

```python
# Teste cada imagem e compare com ID cadastrado
for student_id, images in dataset.items():
    for img_path in images:
        with open(img_path, 'rb') as f:
            response = requests.post(
                "http://localhost:8001/comparison/test-single",
                files={"foto": f},
                data={"ground_truth_id": student_id}
            )
            print(response.json())
```

## ğŸ¯ RecomendaÃ§Ãµes

1. **Dataset de Teste:**
   - MÃ­nimo 5 alunos com 3-5 imagens cada
   - Inclua variaÃ§Ãµes (Ã³culos, barba, iluminaÃ§Ã£o diferente)
   - Separe treino (cadastro) e teste (validaÃ§Ã£o)

2. **ConfiguraÃ§Ã£o DeepFace:**
   - Para melhor precisÃ£o: `Facenet512` ou `ArcFace`
   - Para velocidade: `OpenFace` ou `Dlib`
   - Detector: `opencv` (rÃ¡pido) ou `mtcnn` (preciso)

3. **ExecuÃ§Ã£o:**
   - Rode mÃºltiplos testes para validar consistÃªncia
   - Use GPU para DeepFace se disponÃ­vel
   - Compare diferentes thresholds

4. **AnÃ¡lise:**
   - Foque em Cohen's Kappa para avaliaÃ§Ã£o geral
   - Use F1 Macro para datasets desbalanceados
   - Considere tempo de processamento para produÃ§Ã£o

## ğŸ› Troubleshooting

### Erro: "No face detected"
- Verifique qualidade das imagens
- Tente outro detector (`mtcnn`, `retinaface`)
- Melhore iluminaÃ§Ã£o das fotos

### Baixa Accuracy em ambos
- Dataset pode estar com labels incorretos
- Imagens muito diferentes entre treino e teste
- Verificar se faces estÃ£o cadastradas corretamente

### DeepFace muito lento
- Instale TensorFlow com GPU
- Use modelo mais leve (`OpenFace`)
- Reduza resoluÃ§Ã£o das imagens

## ğŸ“ PrÃ³ximos Passos

ApÃ³s a comparaÃ§Ã£o, vocÃª pode:
1. Atualizar `face_service.py` para usar o modelo vencedor
2. Implementar sistema hÃ­brido (rÃ¡pido + preciso)
3. Ajustar thresholds baseado nas mÃ©tricas
4. Criar pipeline de retreinamento contÃ­nuo

---

**Criado por:** Sistema de ComparaÃ§Ã£o de Modelos
**VersÃ£o:** 1.0.0
**Data:** Novembro 2025
